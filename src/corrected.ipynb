{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UimdHbkxkKAZ"
      },
      "source": [
        "# Corrected Dataset\n",
        "\n",
        "The corrected dataset can be found [here](https://drive.google.com/drive/folders/10TXXa6B_D4AKuBV085tX7UudH1hINBRJ).\n",
        "\n",
        "This dataset is organized into the following folders: \n",
        "* False Parasitized\n",
        "* False Uninfected\n",
        "* True Parasitized\n",
        "* True Uninfected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfhsEdWkRZ47"
      },
      "source": [
        "## Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "yMkBrT7YRgic"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import random\n",
        "import pickle\n",
        "import pathlib\n",
        "\n",
        "def show_samples(samples):\n",
        "    x = int(len(samples) / 2)\n",
        "    y = len(samples) - x\n",
        "    for i in range(len(samples)):\n",
        "        plt.subplot(x, y, i + 1)\n",
        "        plt.subplots_adjust(hspace=1)\n",
        "        plt.imshow(samples[i][0], cmap='gray')\n",
        "        plt.title(\"Uninfected\" if samples[i][1] else \"Infected\", loc='center')\n",
        "        plt.ylabel(f\"Height ({samples[i][0].shape[0]})\")\n",
        "        plt.xlabel(f\"Width ({samples[i][0].shape[1]})\")\n",
        "    plt.show()\n",
        "\n",
        "class MalariaDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        self.n_samples = len(dataframe)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataframe[index]\n",
        "        if self.transform: \n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3), \n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 1),\n",
        "            nn.Conv2d(16, 12, 3), \n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 1),\n",
        "            nn.Conv2d(12, 8, 3), \n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 1),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(8 * 19 * 19, 512), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x): \n",
        "        output = self.conv_layers(x)\n",
        "        output = self.fc_layers(output)\n",
        "        return output\n",
        "\n",
        "def evaluate(model, loader): \n",
        "    total_err = 0\n",
        "    total_samples = 0\n",
        "    for images, labels in loader: \n",
        "        total_err += int(((model(images) > 0.0).squeeze().long() != labels).sum())\n",
        "        total_samples += len(labels)\n",
        "    return float(total_err) / total_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJHODFfqSS0x"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLQTiEQRkKAa",
        "outputId": "3392044c-748a-4f40-ee7a-3e4923963e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "njiachN1kQIl"
      },
      "outputs": [],
      "source": [
        "input_size = 64\n",
        "data_dir = f\"/content/drive/MyDrive/APS360/Data/corrected_{input_size}.pickle\"\n",
        "df = pd.read_pickle(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QBYSHCElgOl"
      },
      "outputs": [],
      "source": [
        "# def changeToInt(image): \n",
        "#   image = image * 255\n",
        "#   return image.astype(np.uint8)\n",
        "\n",
        "# def resize(image, size): \n",
        "#   return np.array(Image.fromarray(image).resize(size, resample=Image.BOX))\n",
        "  \n",
        "# df[\"image\"] = df[\"image\"].apply(lambda image: changeToInt(image))\n",
        "# df[\"image\"] = df[\"image\"].apply(lambda x: resize(x, (28, 28)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWA9a2FLxQNG"
      },
      "source": [
        "## Model Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OJsgfNSSxPjb"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1000)\n",
        "np_df = df.to_numpy()\n",
        "np.random.shuffle(np_df)\n",
        "df_trn = np_df[:int(len(np_df) * 0.8)]\n",
        "df_val = np_df[int(len(np_df) * 0.8):]\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = MalariaDataset(df_trn, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_dataset = MalariaDataset(df_val, transform=transforms.ToTensor())\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "num_steps = len(train_loader)\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = CNN()\n",
        "loss = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "model_path = pathlib.Path(f\"/content/drive/MyDrive/APS360/Models/malaria_corrected_bs{batch_size}_lr{learning_rate}\")\n",
        "model_path.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nmm83hCgQlqN"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLsgYZQXzNnt",
        "outputId": "0e69af2f-ba4c-4304-b049-39a872febd8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300, Loss: 0.081750, Validation Error: 0.061139\n",
            "Epoch 2/300, Loss: 0.024062, Validation Error: 0.028302\n",
            "Epoch 3/300, Loss: 0.054863, Validation Error: 0.026125\n",
            "Epoch 4/300, Loss: 0.066525, Validation Error: 0.027758\n",
            "Epoch 5/300, Loss: 0.071794, Validation Error: 0.027213\n",
            "Epoch 6/300, Loss: 0.054551, Validation Error: 0.023403\n",
            "Epoch 7/300, Loss: 0.046548, Validation Error: 0.022678\n",
            "Epoch 8/300, Loss: 0.004271, Validation Error: 0.023222\n",
            "Epoch 9/300, Loss: 0.018773, Validation Error: 0.023041\n",
            "Epoch 10/300, Loss: 0.004302, Validation Error: 0.024673\n",
            "Epoch 11/300, Loss: 0.003260, Validation Error: 0.024855\n",
            "Epoch 12/300, Loss: 0.008499, Validation Error: 0.023222\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(1000)\n",
        "num_epochs = 300\n",
        "\n",
        "train_loss = np.zeros(num_epochs)\n",
        "val_error = np.zeros(num_epochs)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0 \n",
        "    for images, labels in train_loader: \n",
        "        # ensure labels are same size and type\n",
        "        labels = labels.unsqueeze(1).float()\n",
        "        # forward pass\n",
        "        outputs = model(images)\n",
        "        loss_value = loss(outputs, labels)\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "        # for statistics\n",
        "        running_loss += loss_value.item()\n",
        "    # compute average loss \n",
        "    train_loss[epoch] = running_loss / num_steps\n",
        "    # evaluate on validation set\n",
        "    val_error[epoch] = evaluate(model, val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss_value.item():.6f}, Validation Error: {val_error[epoch]:.6f}\")\n",
        "    # save model after each epoch\n",
        "    torch.save(model.state_dict(), model_path / f\"epoch_{epoch+1}\")\n",
        "\n",
        "# show total loss\n",
        "plt.title(\"Total Loss\")\n",
        "plt.plot(range(1, len(train_loss) + 1), train_loss)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "plt.title(\"Validation Error\")\n",
        "plt.plot(range(1, len(val_error) + 1), val_error)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdpxOhKzyFhI"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1CS1DkHTC4T"
      },
      "outputs": [],
      "source": [
        "net = CNN()\n",
        "state = torch.load(model_path / 'epoch_number')\n",
        "net.load_state_dict(state)\n",
        "\n",
        "incorrect = []\n",
        "total_correct = 0\n",
        "for images, labels in val_loader: \n",
        "    output = (net(images) > 0.0).squeeze().long()\n",
        "    for pred, label, image in zip(output, labels, images): \n",
        "        if pred != label: incorrect.append((image, label))\n",
        "        else: total_correct += 1\n",
        "accuracy = float(total_correct) / len(df_val)\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "incorrect = [[np.transpose(image.numpy(),(2, 1, 0)), label] for (image, label) in incorrect]\n",
        "print(f\"Number of Incorrect Images: {len(incorrect)}\")\n",
        "\n",
        "for i in range(0, 18, 6): \n",
        "    show_samples(incorrect[i:i+6])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "corrected.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
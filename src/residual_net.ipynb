{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Network\n",
    "\n",
    "A residual network uses residual blocks that have skip connections to allow for deep networks. \n",
    "\n",
    "The skip connections allow the model to overcome the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# works best with len(samples) = 2, 4, 6\n",
    "def show_samples(samples):\n",
    "    y = int(len(samples) / 2)\n",
    "    for i in range(len(samples)):\n",
    "        plt.subplot(2, y, i + 1)\n",
    "        plt.subplots_adjust(hspace=1, wspace=1)\n",
    "        plt.imshow(samples[i][0])\n",
    "        plt.title(\"Uninfected\" if samples[i][1] else \"Infected\", loc='center')\n",
    "        plt.ylabel(f\"Height ({samples[i][0].shape[0]})\")\n",
    "        plt.xlabel(f\"Width ({samples[i][0].shape[1]})\")\n",
    "    plt.show()\n",
    "\n",
    "class MalariaDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.dataframe[index]\n",
    "        if self.transform: \n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "def get_loader(df, batch_size=32, transform=None): \n",
    "    dataset = MalariaDataset(df, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module): \n",
    "    def __init__(self, channels, stride=1): \n",
    "        assert len(channels) == 3\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(channels[0], channels[1], 3, stride=stride),\n",
    "            nn.BatchNorm2d(channels[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(channels[1], channels[2], 1),\n",
    "            nn.BatchNorm2d(channels[2]),\n",
    "        )\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(channels[0], channels[2], 3, stride=stride),\n",
    "            nn.BatchNorm2d(channels[2]),\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, input): \n",
    "        return self.relu(self.block(input) + self.shortcut(input))\n",
    "\n",
    "class ResidualNet(nn.Module): \n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.Encoder = nn.Sequential(\n",
    "            ResidualBlock([3, 16, 32]), \n",
    "            ResidualBlock([32, 48, 64]),\n",
    "            ResidualBlock([64, 96, 128]),\n",
    "            ResidualBlock([128, 96, 32]), \n",
    "            ResidualBlock([32, 28, 24]), \n",
    "            ResidualBlock([24, 16, 8]),\n",
    "        )\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8 * 20 * 20, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1), \n",
    "        )\n",
    "    \n",
    "    def forward(self, input): \n",
    "        output = self.Encoder(input)\n",
    "        # print(output.shape)\n",
    "        output = self.FC(output)\n",
    "        return output\n",
    "\n",
    "def evaluate(model, loader): \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images) \n",
    "        total_correct += int(((outputs > 0.0).squeeze().long() == labels).sum())\n",
    "        total_samples += len(labels)\n",
    "    return float(total_correct) / total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32\n",
    "data_dir = f\"../data/corrected_{input_size}.pickle\"\n",
    "df = pd.read_pickle(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "df[\"image\"] = df[\"image\"].apply(lambda x: transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_df = df.to_numpy()\n",
    "np.random.seed(1000)\n",
    "np.random.shuffle(np_df)\n",
    "\n",
    "num_samples = len(np_df)\n",
    "a = int(num_samples * 0.8)\n",
    "b = int(num_samples * 0.9)\n",
    "df_trn = np_df[:a]\n",
    "df_val = np_df[a:b]\n",
    "df_tst = np_df[b:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loaders \n",
    "\n",
    "We can apply random transformations for the training data to have data augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "trn_transform = transforms.Compose([\n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.25),\n",
    "    transforms.RandomAffine(degrees=5, translate=(0.05, 0.05)),\n",
    "    transforms.RandomRotation(180), \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "])\n",
    "\n",
    "trn_loader = get_loader(df_trn, batch_size=batch_size, transform=trn_transform)\n",
    "val_loader = get_loader(df_val, batch_size=batch_size)\n",
    "tst_loader = get_loader(df_tst, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "\n",
    "model = ResidualNet().to(device)\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that the model architecture is functional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, _ in trn_loader: \n",
    "    images = images.to(device)\n",
    "    outputs = model(images)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/100, Training Loss: 0.028609, Training Accuracy: 0.913000, Validation Accuracy: 0.980044\n",
      "Epoch: 002/100, Training Loss: 0.011318, Training Accuracy: 0.972512, Validation Accuracy: 0.979318\n",
      "Epoch: 003/100, Training Loss: 0.037767, Training Accuracy: 0.974100, Validation Accuracy: 0.977504\n",
      "Epoch: 004/100, Training Loss: 0.012553, Training Accuracy: 0.975733, Validation Accuracy: 0.975327\n",
      "Epoch: 005/100, Training Loss: 0.015300, Training Accuracy: 0.975415, Validation Accuracy: 0.977504\n",
      "Epoch: 006/100, Training Loss: 0.007210, Training Accuracy: 0.976368, Validation Accuracy: 0.979318\n",
      "Epoch: 007/100, Training Loss: 0.015045, Training Accuracy: 0.977139, Validation Accuracy: 0.979318\n",
      "Epoch: 008/100, Training Loss: 0.012359, Training Accuracy: 0.977638, Validation Accuracy: 0.982221\n",
      "Epoch: 009/100, Training Loss: 0.016052, Training Accuracy: 0.978227, Validation Accuracy: 0.981495\n",
      "Epoch: 010/100, Training Loss: 0.008965, Training Accuracy: 0.977320, Validation Accuracy: 0.981132\n",
      "Epoch: 011/100, Training Loss: 0.012232, Training Accuracy: 0.978318, Validation Accuracy: 0.982221\n",
      "Epoch: 012/100, Training Loss: 0.022949, Training Accuracy: 0.978409, Validation Accuracy: 0.982583\n",
      "Epoch: 013/100, Training Loss: 0.008496, Training Accuracy: 0.978046, Validation Accuracy: 0.981132\n",
      "Epoch: 014/100, Training Loss: 0.009545, Training Accuracy: 0.979361, Validation Accuracy: 0.981858\n",
      "Epoch: 015/100, Training Loss: 0.024105, Training Accuracy: 0.977683, Validation Accuracy: 0.981858\n",
      "Epoch: 016/100, Training Loss: 0.049335, Training Accuracy: 0.979588, Validation Accuracy: 0.981495\n",
      "Epoch: 017/100, Training Loss: 0.018367, Training Accuracy: 0.980132, Validation Accuracy: 0.982946\n",
      "Epoch: 018/100, Training Loss: 0.008329, Training Accuracy: 0.980631, Validation Accuracy: 0.983672\n",
      "Epoch: 019/100, Training Loss: 0.011746, Training Accuracy: 0.980132, Validation Accuracy: 0.982221\n",
      "Epoch: 020/100, Training Loss: 0.021307, Training Accuracy: 0.980132, Validation Accuracy: 0.983672\n",
      "Epoch: 021/100, Training Loss: 0.021794, Training Accuracy: 0.978998, Validation Accuracy: 0.982221\n",
      "Epoch: 022/100, Training Loss: 0.006355, Training Accuracy: 0.981539, Validation Accuracy: 0.982583\n",
      "Epoch: 023/100, Training Loss: 0.018820, Training Accuracy: 0.980042, Validation Accuracy: 0.984398\n",
      "Epoch: 024/100, Training Loss: 0.011907, Training Accuracy: 0.981584, Validation Accuracy: 0.983672\n",
      "Epoch: 025/100, Training Loss: 0.027307, Training Accuracy: 0.980722, Validation Accuracy: 0.982583\n",
      "Epoch: 026/100, Training Loss: 0.014355, Training Accuracy: 0.981720, Validation Accuracy: 0.982583\n",
      "Epoch: 027/100, Training Loss: 0.018229, Training Accuracy: 0.981720, Validation Accuracy: 0.983309\n",
      "Epoch: 028/100, Training Loss: 0.013537, Training Accuracy: 0.981720, Validation Accuracy: 0.982946\n",
      "Epoch: 029/100, Training Loss: 0.011727, Training Accuracy: 0.981675, Validation Accuracy: 0.982583\n",
      "Epoch: 030/100, Training Loss: 0.015908, Training Accuracy: 0.981629, Validation Accuracy: 0.981495\n",
      "Epoch: 031/100, Training Loss: 0.041579, Training Accuracy: 0.981856, Validation Accuracy: 0.980769\n",
      "Epoch: 032/100, Training Loss: 0.020230, Training Accuracy: 0.981085, Validation Accuracy: 0.981858\n",
      "Epoch: 033/100, Training Loss: 0.041935, Training Accuracy: 0.980858, Validation Accuracy: 0.981495\n",
      "Epoch: 034/100, Training Loss: 0.024935, Training Accuracy: 0.981675, Validation Accuracy: 0.983309\n",
      "Epoch: 035/100, Training Loss: 0.014155, Training Accuracy: 0.982355, Validation Accuracy: 0.984035\n",
      "Epoch: 036/100, Training Loss: 0.024780, Training Accuracy: 0.981947, Validation Accuracy: 0.982221\n",
      "Epoch: 037/100, Training Loss: 0.012392, Training Accuracy: 0.980541, Validation Accuracy: 0.982946\n",
      "Epoch: 038/100, Training Loss: 0.012219, Training Accuracy: 0.981811, Validation Accuracy: 0.984035\n",
      "Epoch: 039/100, Training Loss: 0.034249, Training Accuracy: 0.981266, Validation Accuracy: 0.985123\n",
      "Epoch: 040/100, Training Loss: 0.015898, Training Accuracy: 0.981720, Validation Accuracy: 0.984035\n",
      "Epoch: 041/100, Training Loss: 0.010473, Training Accuracy: 0.982083, Validation Accuracy: 0.983309\n",
      "Epoch: 042/100, Training Loss: 0.013866, Training Accuracy: 0.982537, Validation Accuracy: 0.982221\n",
      "Epoch: 043/100, Training Loss: 0.038639, Training Accuracy: 0.982128, Validation Accuracy: 0.982946\n",
      "Epoch: 044/100, Training Loss: 0.029302, Training Accuracy: 0.981266, Validation Accuracy: 0.982221\n",
      "Epoch: 045/100, Training Loss: 0.025320, Training Accuracy: 0.981765, Validation Accuracy: 0.982583\n",
      "Epoch: 046/100, Training Loss: 0.012898, Training Accuracy: 0.982537, Validation Accuracy: 0.983672\n",
      "Epoch: 047/100, Training Loss: 0.018391, Training Accuracy: 0.983262, Validation Accuracy: 0.982946\n",
      "Epoch: 048/100, Training Loss: 0.015022, Training Accuracy: 0.983081, Validation Accuracy: 0.978955\n",
      "Epoch: 049/100, Training Loss: 0.021909, Training Accuracy: 0.982945, Validation Accuracy: 0.982583\n",
      "Epoch: 050/100, Training Loss: 0.026845, Training Accuracy: 0.983126, Validation Accuracy: 0.983672\n",
      "Epoch: 051/100, Training Loss: 0.028906, Training Accuracy: 0.982355, Validation Accuracy: 0.981858\n",
      "Epoch: 052/100, Training Loss: 0.010174, Training Accuracy: 0.983035, Validation Accuracy: 0.983309\n",
      "Epoch: 053/100, Training Loss: 0.025285, Training Accuracy: 0.982718, Validation Accuracy: 0.982946\n",
      "Epoch: 054/100, Training Loss: 0.005514, Training Accuracy: 0.982854, Validation Accuracy: 0.982221\n",
      "Epoch: 055/100, Training Loss: 0.017206, Training Accuracy: 0.981856, Validation Accuracy: 0.980044\n",
      "Epoch: 056/100, Training Loss: 0.009644, Training Accuracy: 0.983489, Validation Accuracy: 0.982583\n",
      "Epoch: 057/100, Training Loss: 0.009592, Training Accuracy: 0.983172, Validation Accuracy: 0.980769\n",
      "Epoch: 058/100, Training Loss: 0.014617, Training Accuracy: 0.982854, Validation Accuracy: 0.981495\n",
      "Epoch: 059/100, Training Loss: 0.018355, Training Accuracy: 0.982854, Validation Accuracy: 0.981132\n",
      "Epoch: 060/100, Training Loss: 0.018283, Training Accuracy: 0.983580, Validation Accuracy: 0.982583\n",
      "Epoch: 061/100, Training Loss: 0.053486, Training Accuracy: 0.983308, Validation Accuracy: 0.981495\n",
      "Epoch: 062/100, Training Loss: 0.006614, Training Accuracy: 0.983489, Validation Accuracy: 0.984035\n",
      "Epoch: 063/100, Training Loss: 0.038672, Training Accuracy: 0.983807, Validation Accuracy: 0.984398\n",
      "Epoch: 064/100, Training Loss: 0.013344, Training Accuracy: 0.984487, Validation Accuracy: 0.982583\n",
      "Epoch: 065/100, Training Loss: 0.035862, Training Accuracy: 0.983671, Validation Accuracy: 0.982583\n",
      "Epoch: 066/100, Training Loss: 0.047605, Training Accuracy: 0.983625, Validation Accuracy: 0.981495\n",
      "Epoch: 067/100, Training Loss: 0.032212, Training Accuracy: 0.983308, Validation Accuracy: 0.981132\n",
      "Epoch: 068/100, Training Loss: 0.037488, Training Accuracy: 0.984532, Validation Accuracy: 0.983672\n",
      "Epoch: 069/100, Training Loss: 0.021044, Training Accuracy: 0.984215, Validation Accuracy: 0.981858\n",
      "Epoch: 070/100, Training Loss: 0.023029, Training Accuracy: 0.984351, Validation Accuracy: 0.979318\n",
      "Epoch: 071/100, Training Loss: 0.054736, Training Accuracy: 0.984169, Validation Accuracy: 0.981495\n",
      "Epoch: 072/100, Training Loss: 0.020370, Training Accuracy: 0.984351, Validation Accuracy: 0.983309\n",
      "Epoch: 073/100, Training Loss: 0.009719, Training Accuracy: 0.982809, Validation Accuracy: 0.982946\n",
      "Epoch: 074/100, Training Loss: 0.012938, Training Accuracy: 0.984124, Validation Accuracy: 0.981495\n",
      "Epoch: 075/100, Training Loss: 0.031226, Training Accuracy: 0.984442, Validation Accuracy: 0.982221\n",
      "Epoch: 076/100, Training Loss: 0.017419, Training Accuracy: 0.984532, Validation Accuracy: 0.982583\n",
      "Epoch: 077/100, Training Loss: 0.028195, Training Accuracy: 0.984215, Validation Accuracy: 0.980769\n",
      "Epoch: 078/100, Training Loss: 0.016975, Training Accuracy: 0.984895, Validation Accuracy: 0.980769\n",
      "Epoch: 079/100, Training Loss: 0.029615, Training Accuracy: 0.984986, Validation Accuracy: 0.982583\n",
      "Epoch: 080/100, Training Loss: 0.017848, Training Accuracy: 0.984759, Validation Accuracy: 0.982583\n",
      "Epoch: 081/100, Training Loss: 0.030855, Training Accuracy: 0.985394, Validation Accuracy: 0.982583\n",
      "Epoch: 082/100, Training Loss: 0.013455, Training Accuracy: 0.984759, Validation Accuracy: 0.982221\n",
      "Epoch: 083/100, Training Loss: 0.017477, Training Accuracy: 0.984850, Validation Accuracy: 0.981858\n",
      "Epoch: 084/100, Training Loss: 0.033580, Training Accuracy: 0.984623, Validation Accuracy: 0.983309\n",
      "Epoch: 085/100, Training Loss: 0.062026, Training Accuracy: 0.985621, Validation Accuracy: 0.982946\n",
      "Epoch: 086/100, Training Loss: 0.016212, Training Accuracy: 0.985394, Validation Accuracy: 0.982946\n",
      "Epoch: 087/100, Training Loss: 0.024560, Training Accuracy: 0.985576, Validation Accuracy: 0.983672\n",
      "Epoch: 088/100, Training Loss: 0.011764, Training Accuracy: 0.985893, Validation Accuracy: 0.981495\n",
      "Epoch: 089/100, Training Loss: 0.012881, Training Accuracy: 0.985440, Validation Accuracy: 0.983672\n",
      "Epoch: 090/100, Training Loss: 0.041267, Training Accuracy: 0.985848, Validation Accuracy: 0.982946\n",
      "Epoch: 091/100, Training Loss: 0.025239, Training Accuracy: 0.985077, Validation Accuracy: 0.982221\n",
      "Epoch: 092/100, Training Loss: 0.022190, Training Accuracy: 0.985938, Validation Accuracy: 0.981495\n",
      "Epoch: 093/100, Training Loss: 0.014448, Training Accuracy: 0.985938, Validation Accuracy: 0.983309\n",
      "Epoch: 094/100, Training Loss: 0.009894, Training Accuracy: 0.986846, Validation Accuracy: 0.981495\n",
      "Epoch: 095/100, Training Loss: 0.030849, Training Accuracy: 0.986120, Validation Accuracy: 0.981132\n",
      "Epoch: 096/100, Training Loss: 0.013745, Training Accuracy: 0.986211, Validation Accuracy: 0.980769\n",
      "Epoch: 097/100, Training Loss: 0.037212, Training Accuracy: 0.986574, Validation Accuracy: 0.981132\n",
      "Epoch: 098/100, Training Loss: 0.026051, Training Accuracy: 0.986574, Validation Accuracy: 0.981858\n",
      "Epoch: 099/100, Training Loss: 0.021986, Training Accuracy: 0.985349, Validation Accuracy: 0.981858\n",
      "Epoch: 100/100, Training Loss: 0.012752, Training Accuracy: 0.986710, Validation Accuracy: 0.983672\n",
      "Best Validation Accuracy was 0.9851233671988389 at Epoch 39\n"
     ]
    }
   ],
   "source": [
    "try: os.mkdir(\"./residual_net_0\")\n",
    "except: assert os.path.isdir(\"./residual_net_0\")\n",
    "\n",
    "best = {\n",
    "    \"epoch\": 0, \n",
    "    \"accuracy\": 0\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for images, labels in trn_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "        labels = labels.to(device)\n",
    "        # forward pass \n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, axis=1)\n",
    "        # loss value\n",
    "        loss = loss_function(outputs, labels)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # training accuracy \n",
    "        total_correct += int(((outputs > 0.0) == labels).sum())\n",
    "        total_samples += len(labels)\n",
    "    training_accuracy = float(total_correct) / total_samples\n",
    "    validation_accuracy = evaluate(model, val_loader)\n",
    "    if validation_accuracy > best[\"accuracy\"]: \n",
    "        best[\"accuracy\"] = validation_accuracy\n",
    "        best[\"epoch\"] = epoch + 1\n",
    "    print(f\"Epoch: {'%.3d' % (epoch + 1)}/{num_epochs}, Training Loss: {loss.item():.6f}, Training Accuracy: {training_accuracy:.6f}, Validation Accuracy: {validation_accuracy:.6f}\")\n",
    "    torch.save(model.state_dict(), f\"./residual_net_0/epoch_{epoch + 1}.pt\")\n",
    "    scheduler.step()\n",
    "\n",
    "print(f\"Best Validation Accuracy was {best['accuracy']} at Epoch {best['epoch']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "Now we can evaluate the model on the testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "model = ResidualNet()\n",
    "model.load_state_dict(torch.load(f\"./best_models/residual_net_98_73.pt\"))\n",
    "model.to(device)\n",
    "print(\"Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.9836719883889695\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "testing_accuracy = evaluate(model, tst_loader)\n",
    "print(f\"Testing Accuracy: {testing_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Accuracy is 98.37%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09acf7c6190128958c2f4d29ef05b39ae6a25197494ca82b8d6c155c7139327c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

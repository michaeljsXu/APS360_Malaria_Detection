{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UimdHbkxkKAZ"
      },
      "source": [
        "# Autoencoder\n",
        "\n",
        "An **Autoencoder** is a neural network that first compresses the input data into a lower dimensional latent space and then reconstructs the output from this representation. \n",
        "\n",
        "To train an autoencoder for the task of classification, there are three steps. \n",
        "\n",
        "1. Train the full autoencoder model with encoder and decoder. \n",
        "   * The Mean Square Error (MSE) loss function can be used to calculate the loss of the reconstructed images.\n",
        "2. Replace the decoder with fully connected layers, freeze the encoder layers, and train the model on classification. \n",
        "   * This allows the fully connected layers to learn the image features without changing the encoder's weights and bias. \n",
        "   * The Cross Entropy loss function can be used to calculate the loss. \n",
        "3. Unfreeze the encoder layers and train the model. This will lead to better performance by the model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfhsEdWkRZ47"
      },
      "source": [
        "## Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "yMkBrT7YRgic"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import random\n",
        "import pickle\n",
        "import pathlib\n",
        "\n",
        "def show_samples(samples):\n",
        "    x = int(len(samples) / 2)\n",
        "    y = len(samples) - x\n",
        "    for i in range(len(samples)):\n",
        "        plt.subplot(x, y, i + 1)\n",
        "        plt.subplots_adjust(hspace=1)\n",
        "        plt.imshow(samples[i][0], cmap='gray')\n",
        "        plt.title(\"Uninfected\" if samples[i][1] else \"Infected\", loc='center')\n",
        "        plt.ylabel(f\"Height ({samples[i][0].shape[0]})\")\n",
        "        plt.xlabel(f\"Width ({samples[i][0].shape[1]})\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class MalariaDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        self.n_samples = len(dataframe)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataframe[index]\n",
        "        if self.transform: \n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "        # 32 - 30 - 15 - 13 - 6 - 4 - 2\n",
        "        self.Encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3), \n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(2), \n",
        "            nn.Conv2d(16, 8, 3), \n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(2), \n",
        "            nn.ReLU(), \n",
        "            nn.Conv2d(8, 4, 3), \n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        # 2 - 4 - 6 - 12 - 14 - 28 - 30 - 32\n",
        "        self.Decoder = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode='nearest'), \n",
        "            nn.ConvTranspose2d(4, 8, 3), \n",
        "            nn.ReLU(), \n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.ConvTranspose2d(8, 16, 3), \n",
        "            nn.ReLU(), \n",
        "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "            nn.ConvTranspose2d(16, 16, 3), \n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 3, 3), \n",
        "            nn.ReLU(),\n",
        "        )\n",
        "    \n",
        "    def forward(self, input): \n",
        "        output = self.Encoder(input)\n",
        "        output = self.Decoder(output)\n",
        "        return output\n",
        "        \n",
        "\n",
        "class Encoder(nn.Module): \n",
        "    def __init__(self): \n",
        "        super().__init__()\n",
        "        self.Encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3), \n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(2, 1), \n",
        "            nn.Conv2d(16, 8, 3), \n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(2, 1), \n",
        "            nn.ReLU(), \n",
        "            nn.Conv2d(8, 4, 3), \n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(2, 1),\n",
        "        )\n",
        "        self.FC = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(4 * 23 * 23, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 16), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1),\n",
        "        )\n",
        "    \n",
        "    def forward(self, input): \n",
        "        output = self.Encoder(input)\n",
        "        # print(output.shape)\n",
        "        output = self.FC(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "def evaluate(model, loader): \n",
        "    total_err = 0\n",
        "    total_samples = 0\n",
        "    for images, labels in loader: \n",
        "        total_err += int(((model(images) > 0.0).squeeze().long() != labels).sum())\n",
        "        total_samples += len(labels)\n",
        "    return float(total_err) / total_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJHODFfqSS0x"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "njiachN1kQIl"
      },
      "outputs": [],
      "source": [
        "input_size = 32\n",
        "data_dir = f\"../data/corrected_{input_size}.pickle\"\n",
        "df = pd.read_pickle(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "yqVjwRCsyrkC"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1000)\n",
        "np_df = df.to_numpy()\n",
        "np.random.shuffle(np_df)\n",
        "df_trn = np_df[:int(len(np_df) * 0.8)]\n",
        "df_val = np_df[int(len(np_df) * 0.8):]\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = MalariaDataset(df_trn, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "val_dataset = MalariaDataset(df_val, transform=transforms.ToTensor())\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mygWHJIWxiOA"
      },
      "source": [
        "## Full Autoencoder\n",
        "\n",
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxwVnH_MymOp",
        "outputId": "e40efc52-77d1-49ae-ec7c-994cf1425d63"
      },
      "outputs": [],
      "source": [
        "num_steps = len(train_loader)\n",
        "learning_rate = 0.001\n",
        "num_epochs = 300\n",
        "\n",
        "torch.manual_seed(1000)\n",
        "model = Autoencoder()\n",
        "loss = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF7jan5XzZaK"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "pvVdlewkA19s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/10, Loss: 0.0343\n",
            "Epoch: 2/10, Loss: 0.0173\n",
            "Epoch: 3/10, Loss: 0.0157\n",
            "Epoch: 4/10, Loss: 0.0148\n",
            "Epoch: 5/10, Loss: 0.0141\n",
            "Epoch: 6/10, Loss: 0.0135\n",
            "Epoch: 7/10, Loss: 0.0128\n",
            "Epoch: 8/10, Loss: 0.0122\n",
            "Epoch: 9/10, Loss: 0.0120\n",
            "Epoch: 10/10, Loss: 0.0118\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    for images, _ in train_loader: \n",
        "        # forward pass\n",
        "        outputs = model(images)\n",
        "        loss_value = loss(outputs, images)\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "        # loss \n",
        "        running_loss += loss_value.item()\n",
        "    print(f\"Epoch: {epoch + 1}/{num_epochs}, Loss: {float(running_loss) / num_steps:.4f}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"encoder.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWA9a2FLxQNG"
      },
      "source": [
        "## Freezing Encoder Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for param in model.parameters(): \n",
        "    print(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Jp8jhRYA-_P"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder()\n",
        "\n",
        "for i, (encoder_param, param) in enumerate(zip(encoder.parameters(), model.parameters())): \n",
        "    if i < 6: \n",
        "        encoder_param.data = torch.clone(param.data)\n",
        "        encoder_param.requires_grad = False\n",
        "\n",
        "loss = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(encoder.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, param in enumerate(encoder.parameters()): \n",
        "    print(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 300\n",
        "\n",
        "val_error = np.zeros(num_epochs)\n",
        "\n",
        "for epoch in range(num_epochs): \n",
        "    for images, labels in train_loader: \n",
        "        # ensure labels are same size and type\n",
        "        labels = labels.unsqueeze(1).float()\n",
        "        # forward pass\n",
        "        outputs = encoder(images)\n",
        "        loss_value = loss(outputs, labels)\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "    # evaluate on validation set\n",
        "    val_error[epoch] = evaluate(encoder, val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss_value.item():.6f}, Validation Error: {val_error[epoch]:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbdH679mA5vn"
      },
      "source": [
        "## Unfreezing Encoder Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "FlvwgEY_A8UR"
      },
      "outputs": [],
      "source": [
        "for i, param in enumerate(encoder.parameters()): \n",
        "    if i < 6: param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = pathlib.Path(f\"./models/autoencoder_bs{batch_size}_lr{learning_rate}\")\n",
        "model_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "num_epochs = 300 \n",
        "\n",
        "train_loss = np.zeros(num_epochs)\n",
        "val_error = np.zeros(num_epochs)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0 \n",
        "    for images, labels in train_loader: \n",
        "        # ensure labels are same size and type\n",
        "        labels = labels.unsqueeze(1).float()\n",
        "        # forward pass\n",
        "        outputs = encoder(images)\n",
        "        loss_value = loss(outputs, labels)\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss_value.backward()\n",
        "        optimizer.step()\n",
        "        # for statistics\n",
        "        running_loss += loss_value.item()\n",
        "    # compute average loss \n",
        "    train_loss[epoch] = running_loss / num_steps\n",
        "    # evaluate on validation set\n",
        "    val_error[epoch] = evaluate(encoder, val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss_value.item():.6f}, Validation Error: {val_error[epoch]:.6f}\")\n",
        "    # save model after each epoch\n",
        "    torch.save(encoder.state_dict(), model_path / f\"epoch_{epoch+1}\")\n",
        "\n",
        "# show total loss\n",
        "plt.title(\"Total Loss\")\n",
        "plt.plot(range(1, len(train_loss) + 1), train_loss)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "plt.title(\"Validation Error\")\n",
        "plt.plot(range(1, len(val_error) + 1), val_error)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "autoencoder.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
